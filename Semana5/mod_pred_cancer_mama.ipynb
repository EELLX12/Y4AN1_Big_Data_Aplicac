{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f85b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, socket\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cf915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark: 3.5.4\n",
      "Driver Python: d:\\magali\\ciencia de datos UCI\\Cuarto\\big data aplicada\\IC\\Y4AN1_Big_Data_Aplicac\\venv_bda\\Scripts\\python.exe\n",
      "Cuenta JVM: 10\n",
      "Worker Python: d:\\magali\\ciencia de datos UCI\\Cuarto\\big data aplicada\\IC\\Y4AN1_Big_Data_Aplicac\\venv_bda\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Crear Sesión Spark\n",
    "# =============================\n",
    "# --- Entorno base (mismo Python del venv para driver/worker) ---\n",
    "this_python = sys.executable\n",
    "os.environ[\"PYSPARK_PYTHON\"] = this_python\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = this_python\n",
    "os.environ[\"SPARK_LOCAL_IP\"] = \"127.0.0.1\"\n",
    "\n",
    "spark_tmp = r\"C:\\spark-tmp\"\n",
    "Path(spark_tmp).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Variables críticas de Windows que a veces NO llegan al executor desde Notebook ---\n",
    "win_keys = [\n",
    "    \"SystemRoot\", \"ComSpec\", \"PATHEXT\", \"WINDIR\", \"USERPROFILE\",\n",
    "    \"HOMEDRIVE\", \"HOMEPATH\", \"TEMP\", \"TMP\", \"NUMBER_OF_PROCESSORS\", \"PROCESSOR_ARCHITECTURE\"\n",
    "]\n",
    "executor_env = {k: os.environ[k] for k in win_keys if k in os.environ}\n",
    "\n",
    "# Para depurar: también pasamos PATH y PYTHONPATH actuales del kernel\n",
    "executor_env[\"PATH\"] = os.environ.get(\"PATH\", \"\")\n",
    "executor_env[\"PYTHONPATH\"] = os.pathsep.join(sys.path)\n",
    "executor_env[\"PYSPARK_PYTHON\"] = this_python\n",
    "executor_env[\"PYSPARK_DRIVER_PYTHON\"] = this_python\n",
    "executor_env[\"TEMP\"] = spark_tmp\n",
    "executor_env[\"TMP\"] = spark_tmp\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"NotebookSafe-EnvFix\")\n",
    "    .master(\"local[1]\")  # primero 1 worker; luego podrás subir a local[*]\n",
    "    .config(\"spark.driver.bindAddress\",\"127.0.0.1\")\n",
    "    .config(\"spark.driver.host\",\"127.0.0.1\")\n",
    "    .config(\"spark.local.dir\", spark_tmp)\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\",\"false\")\n",
    "    .config(\"spark.python.worker.reuse\",\"false\")\n",
    "    .config(\"spark.port.maxRetries\",\"64\")\n",
    "    .config(\"spark.pyspark.python\", this_python)\n",
    "    .config(\"spark.pyspark.driver.python\", this_python)\n",
    "    .config(\"spark.driver.extraJavaOptions\",\"-Djava.net.preferIPv4Stack=true\")\n",
    "    .config(\"spark.executor.extraJavaOptions\",\"-Djava.net.preferIPv4Stack=true\")\n",
    ")\n",
    "\n",
    "# Inyecta todas las env vars al EXECUTOR\n",
    "for k, v in executor_env.items():\n",
    "    builder = builder.config(f\"spark.executorEnv.{k}\", v)\n",
    "\n",
    "spark = builder.getOrCreate()\n",
    "\n",
    "print(\"Spark:\", spark.version)\n",
    "print(\"Driver Python:\", sys.executable)\n",
    "print(\"Cuenta JVM:\", spark.range(10).count())\n",
    "\n",
    "def pyver_in_worker(it):\n",
    "    import sys as _sys\n",
    "    yield \"Worker Python: \" + _sys.executable\n",
    "\n",
    "print(spark.sparkContext.parallelize([0],1).mapPartitions(pyver_in_worker).first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9aad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "subprocess.check_call([sys.executable, \"-c\", \"print('subprocess OK')\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1efa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas generadas: 1500\n"
     ]
    }
   ],
   "source": [
    "# ==================\n",
    "# Data sintética\n",
    "# ==================\n",
    "\n",
    "# Etiqueta: 1 = maligno, 0 = benigno\n",
    "#\n",
    "# Generamos dos distribuciones con separabilidad moderada y ruido:\n",
    "# - Benignos: medias menores, varianzas más compactas\n",
    "# - Malignos: medias mayores en varios rasgos, +correlación aproximada\n",
    "\n",
    "def make_synthetic_breast_cancer(n=1200, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    features = [\n",
    "        \"mean_radius\", \"mean_texture\", \"mean_perimeter\", \"mean_area\",\n",
    "        \"smoothness\", \"compactness\", \"concavity\", \"symmetry\", \"fractal_dim\",\n",
    "        \"mean_density\", \"cell_size_var\", \"nuclei_clump\", \"mitoses\"\n",
    "    ]\n",
    "\n",
    "    # ~40% malignos\n",
    "    n_mal = int(n * 0.40)\n",
    "    n_ben = n - n_mal\n",
    "\n",
    "    # Benignos\n",
    "    mu_b = [12.5, 16.0, 80.0, 500.0, 0.090, 0.070, 0.040, 0.18, 0.055, 0.85, 1.2, 2.0, 1.0]\n",
    "    sd_b = [ 1.5,  2.5, 12.0,  90.0, 0.012, 0.020, 0.015, 0.03,  0.006, 0.08, 0.3, 0.7, 0.6]\n",
    "\n",
    "    # Malignos\n",
    "    mu_m = [17.0, 22.5, 110.0, 950.0, 0.105, 0.120, 0.090, 0.21, 0.062, 1.10, 2.0, 3.5, 1.8]\n",
    "    sd_m = [ 2.0,  3.0,  16.0, 150.0, 0.014, 0.030, 0.020, 0.04,  0.007, 0.10, 0.4, 0.9, 0.7]\n",
    "\n",
    "    def gen_class(n_rows, mu, sd):\n",
    "        X = np.column_stack([rng.normal(loc=mu[i], scale=sd[i], size=n_rows) for i in range(len(mu))])\n",
    "        X = np.maximum(X, 0)  # sin negativos\n",
    "        # Dependencias suaves realistas\n",
    "        X[:, 2] = np.maximum(X[:, 2], X[:, 0] * 5 + rng.normal(0, 5, size=n_rows))        # perimeter ~ 5*radius\n",
    "        X[:, 3] = np.maximum(X[:, 3], (X[:, 0] ** 2) * 3 + rng.normal(0, 80, size=n_rows))# area ~ 3*radius^2\n",
    "        return X\n",
    "\n",
    "    X_b = gen_class(n_ben, mu_b, sd_b)\n",
    "    X_m = gen_class(n_mal, mu_m, sd_m)\n",
    "\n",
    "    y_b = np.zeros((n_ben, 1), dtype=int)\n",
    "    y_m = np.ones((n_mal, 1), dtype=int)\n",
    "\n",
    "    X = np.vstack([X_b, X_m])\n",
    "    y = np.vstack([y_b, y_m]).ravel()\n",
    "\n",
    "    # Mezclar\n",
    "    idx = rng.permutation(len(y))\n",
    "    X = X[idx]; y = y[idx]\n",
    "\n",
    "    pdf = pd.DataFrame(X, columns=features)\n",
    "    pdf[\"label\"] = y\n",
    "    return pdf\n",
    "\n",
    "pdf = make_synthetic_breast_cancer(n=1500, seed=123)\n",
    "print(\"Filas generadas:\", len(pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8e1ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>concavity</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dim</th>\n",
       "      <th>mean_density</th>\n",
       "      <th>cell_size_var</th>\n",
       "      <th>nuclei_clump</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.016416</td>\n",
       "      <td>19.087914</td>\n",
       "      <td>50.186307</td>\n",
       "      <td>459.903624</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>0.075753</td>\n",
       "      <td>0.048606</td>\n",
       "      <td>0.226450</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>0.838194</td>\n",
       "      <td>1.232199</td>\n",
       "      <td>3.121839</td>\n",
       "      <td>1.548933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.109970</td>\n",
       "      <td>21.233005</td>\n",
       "      <td>96.137164</td>\n",
       "      <td>1141.179806</td>\n",
       "      <td>0.093981</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.107445</td>\n",
       "      <td>0.222217</td>\n",
       "      <td>0.065182</td>\n",
       "      <td>1.300904</td>\n",
       "      <td>2.458677</td>\n",
       "      <td>2.973516</td>\n",
       "      <td>0.729266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.726332</td>\n",
       "      <td>19.088364</td>\n",
       "      <td>85.379364</td>\n",
       "      <td>530.028582</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.054609</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>0.047185</td>\n",
       "      <td>0.852006</td>\n",
       "      <td>1.007864</td>\n",
       "      <td>2.225548</td>\n",
       "      <td>0.245449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.526049</td>\n",
       "      <td>17.183792</td>\n",
       "      <td>92.971968</td>\n",
       "      <td>535.146137</td>\n",
       "      <td>0.090336</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>0.057574</td>\n",
       "      <td>0.226720</td>\n",
       "      <td>0.052940</td>\n",
       "      <td>0.925060</td>\n",
       "      <td>1.631703</td>\n",
       "      <td>1.623197</td>\n",
       "      <td>0.749866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.147575</td>\n",
       "      <td>22.799536</td>\n",
       "      <td>97.584910</td>\n",
       "      <td>780.532284</td>\n",
       "      <td>0.121393</td>\n",
       "      <td>0.106319</td>\n",
       "      <td>0.064491</td>\n",
       "      <td>0.237935</td>\n",
       "      <td>0.069361</td>\n",
       "      <td>1.049501</td>\n",
       "      <td>1.412589</td>\n",
       "      <td>3.481713</td>\n",
       "      <td>1.901984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>16.109235</td>\n",
       "      <td>26.004893</td>\n",
       "      <td>125.946846</td>\n",
       "      <td>1121.300327</td>\n",
       "      <td>0.120899</td>\n",
       "      <td>0.135541</td>\n",
       "      <td>0.118529</td>\n",
       "      <td>0.178104</td>\n",
       "      <td>0.069398</td>\n",
       "      <td>1.135080</td>\n",
       "      <td>1.468590</td>\n",
       "      <td>1.857710</td>\n",
       "      <td>2.304726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>10.736741</td>\n",
       "      <td>19.211483</td>\n",
       "      <td>86.571062</td>\n",
       "      <td>533.342556</td>\n",
       "      <td>0.078971</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.063280</td>\n",
       "      <td>0.248974</td>\n",
       "      <td>0.048668</td>\n",
       "      <td>0.850664</td>\n",
       "      <td>0.908038</td>\n",
       "      <td>2.122866</td>\n",
       "      <td>0.304082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>12.881699</td>\n",
       "      <td>14.673539</td>\n",
       "      <td>83.195971</td>\n",
       "      <td>547.067012</td>\n",
       "      <td>0.100714</td>\n",
       "      <td>0.072085</td>\n",
       "      <td>0.053395</td>\n",
       "      <td>0.172453</td>\n",
       "      <td>0.056241</td>\n",
       "      <td>0.823973</td>\n",
       "      <td>1.731577</td>\n",
       "      <td>1.854618</td>\n",
       "      <td>0.236313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>14.128698</td>\n",
       "      <td>25.919282</td>\n",
       "      <td>99.000860</td>\n",
       "      <td>780.386601</td>\n",
       "      <td>0.118191</td>\n",
       "      <td>0.103462</td>\n",
       "      <td>0.109456</td>\n",
       "      <td>0.155103</td>\n",
       "      <td>0.058645</td>\n",
       "      <td>0.944172</td>\n",
       "      <td>1.679150</td>\n",
       "      <td>3.079903</td>\n",
       "      <td>1.098214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>11.483418</td>\n",
       "      <td>14.179924</td>\n",
       "      <td>63.825045</td>\n",
       "      <td>575.089541</td>\n",
       "      <td>0.120340</td>\n",
       "      <td>0.090902</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>0.216451</td>\n",
       "      <td>0.050912</td>\n",
       "      <td>0.826338</td>\n",
       "      <td>1.217564</td>\n",
       "      <td>2.130401</td>\n",
       "      <td>0.462364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_radius  mean_texture  mean_perimeter    mean_area  smoothness  \\\n",
       "0       12.016416     19.087914       50.186307   459.903624    0.098730   \n",
       "1       19.109970     21.233005       96.137164  1141.179806    0.093981   \n",
       "2       12.726332     19.088364       85.379364   530.028582    0.085500   \n",
       "3       10.526049     17.183792       92.971968   535.146137    0.090336   \n",
       "4       15.147575     22.799536       97.584910   780.532284    0.121393   \n",
       "...           ...           ...             ...          ...         ...   \n",
       "1495    16.109235     26.004893      125.946846  1121.300327    0.120899   \n",
       "1496    10.736741     19.211483       86.571062   533.342556    0.078971   \n",
       "1497    12.881699     14.673539       83.195971   547.067012    0.100714   \n",
       "1498    14.128698     25.919282       99.000860   780.386601    0.118191   \n",
       "1499    11.483418     14.179924       63.825045   575.089541    0.120340   \n",
       "\n",
       "      compactness  concavity  symmetry  fractal_dim  mean_density  \\\n",
       "0        0.075753   0.048606  0.226450     0.053804      0.838194   \n",
       "1        0.156071   0.107445  0.222217     0.065182      1.300904   \n",
       "2        0.061747   0.054609  0.157271     0.047185      0.852006   \n",
       "3        0.074980   0.057574  0.226720     0.052940      0.925060   \n",
       "4        0.106319   0.064491  0.237935     0.069361      1.049501   \n",
       "...           ...        ...       ...          ...           ...   \n",
       "1495     0.135541   0.118529  0.178104     0.069398      1.135080   \n",
       "1496     0.074400   0.063280  0.248974     0.048668      0.850664   \n",
       "1497     0.072085   0.053395  0.172453     0.056241      0.823973   \n",
       "1498     0.103462   0.109456  0.155103     0.058645      0.944172   \n",
       "1499     0.090902   0.033692  0.216451     0.050912      0.826338   \n",
       "\n",
       "      cell_size_var  nuclei_clump   mitoses  label  \n",
       "0          1.232199      3.121839  1.548933      0  \n",
       "1          2.458677      2.973516  0.729266      1  \n",
       "2          1.007864      2.225548  0.245449      0  \n",
       "3          1.631703      1.623197  0.749866      0  \n",
       "4          1.412589      3.481713  1.901984      1  \n",
       "...             ...           ...       ...    ...  \n",
       "1495       1.468590      1.857710  2.304726      1  \n",
       "1496       0.908038      2.122866  0.304082      0  \n",
       "1497       1.731577      1.854618  0.236313      0  \n",
       "1498       1.679150      3.079903  1.098214      1  \n",
       "1499       1.217564      2.130401  0.462364      0  \n",
       "\n",
       "[1500 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff75a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo en Spark: 1500\n",
      "root\n",
      " |-- mean_radius: double (nullable = true)\n",
      " |-- mean_texture: double (nullable = true)\n",
      " |-- mean_perimeter: double (nullable = true)\n",
      " |-- mean_area: double (nullable = true)\n",
      " |-- smoothness: double (nullable = true)\n",
      " |-- compactness: double (nullable = true)\n",
      " |-- concavity: double (nullable = true)\n",
      " |-- symmetry: double (nullable = true)\n",
      " |-- fractal_dim: double (nullable = true)\n",
      " |-- mean_density: double (nullable = true)\n",
      " |-- cell_size_var: double (nullable = true)\n",
      " |-- nuclei_clump: double (nullable = true)\n",
      " |-- mitoses: double (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.createDataFrame(pdf)\n",
    "\n",
    "print(\"Conteo en Spark:\", sdf.count())\n",
    "sdf.printSchema()\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4cdbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1189 Test: 311\n"
     ]
    }
   ],
   "source": [
    "train_sdf, test_sdf = sdf.randomSplit([0.8, 0.2], seed=2025)\n",
    "print(\"Train:\", train_sdf.count(), \"Test:\", test_sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68dbed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 5) Pipeline de ML\n",
    "# =============================\n",
    "feature_cols = [c for c in sdf.columns if c != \"label\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_raw\")\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\", withMean=True, withStd=True)\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\",\n",
    "                        predictionCol=\"prediction\", probabilityCol=\"probability\")\n",
    "pipe = Pipeline(stages=[assembler, scaler, lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59196797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV completada. Mejor LR -> regParam: 0.0 | elasticNetParam: 0.0\n",
      "AUC promedio (CV): 1.0\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 6) Cross-Validation (k=5)\n",
    "# =============================\n",
    "\n",
    "param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.0, 0.01, 0.05, 0.1])\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "    .build()\n",
    ")\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\",\n",
    "                                          rawPredictionCol=\"rawPrediction\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=pipe,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5,\n",
    "    parallelism=1,   # 0 = auto; cuando todo esté estable puedes subirlo\n",
    "    seed=2025\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "cv_model = cv.fit(train_sdf)\n",
    "\n",
    "# Mejor modelo\n",
    "best_model = cv_model.bestModel\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "bm_lr = [st for st in best_model.stages if isinstance(st, LogisticRegressionModel)][0]\n",
    "\n",
    "print(\"CV completada. Mejor LR -> regParam:\", bm_lr.getRegParam(),\n",
    "      \"| elasticNetParam:\", bm_lr.getElasticNetParam())\n",
    "\n",
    "cv_avg_auc = float(max(cv_model.avgMetrics))\n",
    "print(\"AUC promedio (CV):\", round(cv_avg_auc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0569600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (test): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\magali\\ciencia de datos UCI\\Cuarto\\big data aplicada\\IC\\Y4AN1_Big_Data_Aplicac\\venv_bda\\Lib\\site-packages\\pyspark\\sql\\context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision(1): 1.0\n",
      "Recall(1): 1.0\n",
      "F1(1): 1.0\n",
      "Confusion [[TN,FP],[FN,TP]]:\n",
      " [[183.   0.]\n",
      " [  0. 128.]]\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 7) Evaluación en TEST\n",
    "# =============================\n",
    "pred_test = best_model.transform(test_sdf).cache()\n",
    "auc_test = float(evaluator.evaluate(pred_test))\n",
    "print(\"AUC (test):\", round(auc_test, 4))\n",
    "\n",
    "pred_rdd = pred_test.select(\"prediction\", \"label\").rdd.map(lambda r: (float(r[0]), float(r[1])))\n",
    "metrics = MulticlassMetrics(pred_rdd)\n",
    "\n",
    "accuracy     = float(metrics.accuracy)\n",
    "precision_1  = float(metrics.precision(1.0))\n",
    "recall_1     = float(metrics.recall(1.0))\n",
    "f1_1         = float(metrics.fMeasure(1.0))\n",
    "cm = metrics.confusionMatrix().toArray()\n",
    "tn, fp, fn, tp = int(cm[0,0]), int(cm[0,1]), int(cm[1,0]), int(cm[1,1])\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy, 4))\n",
    "print(\"Precision(1):\", round(precision_1, 4))\n",
    "print(\"Recall(1):\", round(recall_1, 4))\n",
    "print(\"F1(1):\", round(f1_1, 4))\n",
    "print(\"Confusion [[TN,FP],[FN,TP]]:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "223a3eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel guardado en: D:\\magali\\ciencia de datos UCI\\Cuarto\\big data aplicada\\IC\\Y4AN1_Big_Data_Aplicac\\Semana5\\bcancer_sintetico_resultados_20250822_073724.xlsx\n",
      "Proceso completo OK.\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 8) Exportar a Excel (misma carpeta)\n",
    "# =============================\n",
    "out_dir = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = out_dir / f\"bcancer_sintetico_resultados_{ts}.xlsx\"\n",
    "\n",
    "pdf_all  = sdf.toPandas()\n",
    "pdf_pred = pred_test.select(*feature_cols, \"label\", \"prediction\").toPandas()\n",
    "\n",
    "df_cv = pd.DataFrame([{\"metric\": \"AUC_CV_avg\", \"value\": cv_avg_auc}])\n",
    "df_test_metrics = pd.DataFrame([{\n",
    "    \"AUC_test\": auc_test,\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision_pos\": precision_1,\n",
    "    \"Recall_pos\": recall_1,\n",
    "    \"F1_pos\": f1_1\n",
    "}])\n",
    "df_conf = pd.DataFrame([[tn, fp], [fn, tp]],\n",
    "                       columns=[\"Pred_0\", \"Pred_1\"],\n",
    "                       index=[\"Real_0\", \"Real_1\"])\n",
    "\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as w:\n",
    "    pdf_all.to_excel(w, index=False, sheet_name=\"data_sintetica\")\n",
    "    pdf_pred.to_excel(w, index=False, sheet_name=\"pred_test\")\n",
    "    df_cv.to_excel(w, index=False, sheet_name=\"cv_metrics\")\n",
    "    df_test_metrics.to_excel(w, index=False, sheet_name=\"best_model_metrics\")\n",
    "    df_conf.to_excel(w, sheet_name=\"confusion_matrix\")\n",
    "\n",
    "print(f\"Excel guardado en: {out_path.resolve()}\")\n",
    "\n",
    "print(\"Proceso completo OK.\")\n",
    "# spark.stop()  # descomenta si quieres cerrar Spark explícitamente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
